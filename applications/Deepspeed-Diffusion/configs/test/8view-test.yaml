pretrained_model_name_or_path: 'stabilityai/stable-diffusion-2-1-unclip'
pretrained_unet_path: null #'/home/jerasley/xiaoxiawu/mvdiffusion-wonder3d/wonder3d-fullcode/outputs/mvdiffusion-0104-mix-8views-ortho-allattention-b64-threebgs-lvis/'
# pretrained_unet_name: unet-50000
revision: null
data_path: '/home/czh5/multimodal/deepspeed-mvdiffusion/data'
train_dataset:
  root_dir: '/home/czh5/multimodal/deepspeed-mvdiffusion/data/' #'/blob1/3rdparty/obj-render1/objaverse/hf-objaverse-v1/'
  object_list: ${data_path}/data_valid_1231.json
  data_path_num: 1
  num_views: 8
  random_views: true
  groups_num: 1
  bg_color: 'three_choices'
  img_wh: [384, 384]
  validation: false
  num_validation_samples: 8
  # read_normal: true
  # read_color: true
  mix_color_normal: true
validation_dataset:
  root_dir: '/home/czh5/multimodal/deepspeed-mvdiffusion/data/' #'/blob1/3rdparty/obj-render1/objaverse/hf-objaverse-v1/'
  object_list: ${data_path}/data_valid_1231.json
  num_views: 8
  random_views: false
  groups_num: 1
  bg_color: 'white'
  img_wh: [384, 384]
  validation: true
  num_validation_samples: 32
  # read_normal: true
  # read_color: true
  mix_color_normal: true
validation_train_dataset:
  root_dir: '/home/czh5/multimodal/deepspeed-mvdiffusion/data/' #'/blob1/3rdparty/obj-render1/objaverse/hf-objaverse-v1/'
  object_list: ${data_path}/data_valid_1231.json
  num_views: 8
  random_views: true
  groups_num: 1
  bg_color: 'white'
  img_wh: [384, 384]
  validation: true
  num_validation_samples: 32
  num_samples: 32
  # read_normal: true
  # read_color: true
  mix_color_normal: true

pred_type: 'mix'

output_dir: '/home/czh5/multimodal/deepspeed-mvdiffusion/outputs0'
seed: 42
train_batch_size: 4
validation_batch_size: 4
validation_train_batch_size: 4
max_train_steps: 100000
gradient_accumulation_steps: 2
gradient_checkpointing: true
learning_rate: 1e-4
scale_lr: false
lr_scheduler: "constant_with_warmup"
lr_warmup_steps: 100
snr_gamma: 5.0
use_8bit_adam: false
allow_tf32: true
use_ema: true  
dataloader_num_workers: 64
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 1.e-2
adam_epsilon: 1.e-08
max_grad_norm: 1.0
prediction_type: null
vis_dir: vis
logging_dir: logs
mixed_precision: "bf16"
report_to: 'tensorboard'
local_rank: -1
checkpointing_steps: 2500
checkpoints_total_limit: 20
resume_from_checkpoint: latest
enable_xformers_memory_efficient_attention: true
validation_steps: 1250
validation_sanity_check: false
tracker_project_name: 'mvdiffusion-image-v1'

trainable_modules: null
use_classifier_free_guidance: true
condition_drop_rate: 0.05
drop_type: 'drop_as_a_whole'  # modify
camera_embedding_lr_mult: 10.
scale_input_latents: true

pipe_kwargs:
  camera_embedding_type: 'e_de_da_sincos'
  num_views: 8

validation_guidance_scales: [1., 3.]
pipe_validation_kwargs:
  eta: 1.0
validation_grid_nrow: 16

unet_from_pretrained_kwargs:
  camera_embedding_type: 'e_de_da_sincos'
  projection_class_embeddings_input_dim: 10  # modify
  num_views: 8
  sample_size: 48
  zero_init_conv_in: true
  zero_init_camera_projection: false
  cd_attention_last: false
  cd_attention_mid: false
  multiview_attention: true
  sparse_mv_attention: false
  mvcd_attention: false

num_views: 8
camera_embedding_type: 'e_de_da_sincos'
